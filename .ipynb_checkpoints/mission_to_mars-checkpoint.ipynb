{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {\"executable_path\": \"/usr/local/bin/chromedriver\"}\n",
    "browser = Browser(\"chrome\", **executable_path, headless=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After a Reset, Curiosity Is Operating Normally\n",
      "\n",
      "NASA's Mars rover Curiosity is in good health but takes a short break while engineers diagnose why it reset its computer. \n",
      "-----------\n",
      "<div class=\"content_title\"><a href=\"/news/8416/after-a-reset-curiosity-is-operating-normally/\" target=\"_self\">After a Reset, Curiosity Is Operating Normally</a></div>\n"
     ]
    }
   ],
   "source": [
    "# NASA Mars News\n",
    "# HTML object\n",
    "url = \"https://mars.nasa.gov/news/\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "    \n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "# Retrieve titles, summaries of articles\n",
    "titles = soup.find_all(\"div\", class_=\"content_title\")\n",
    "summaries = soup.find_all(\"div\", class_=\"article_teaser_body\")\n",
    "\n",
    "for title in titles:\n",
    "    # Specify title information\n",
    "    link = title.find(\"a\")\n",
    "    title_txt = link.text\n",
    "    \n",
    "    # We only want the first title, so break loop\n",
    "    break\n",
    "    \n",
    "for summary in summaries:\n",
    "    #Specify summary information\n",
    "    summary_txt = summary.text\n",
    "    \n",
    "    # We only want the first summary, so break loop\n",
    "    break\n",
    "    \n",
    "print(title_txt)\n",
    "print()\n",
    "print(summary_txt)\n",
    "print(\"-----------\")\n",
    "print(title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jpl.nasa.gov/spaceimages/images/mediumsize/PIA19964_ip.jpg\n"
     ]
    }
   ],
   "source": [
    "# JPL Mars Space Images\n",
    "# HTML object\n",
    "url = \"https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve image information\n",
    "mars_pics = soup.find_all(\"a\", class_=\"fancybox\")\n",
    "\n",
    "for pic in mars_pics:\n",
    "    # Specify image information\n",
    "    loc = pic[\"data-fancybox-href\"]\n",
    "    featured_image_url = \"https://www.jpl.nasa.gov\" + loc\n",
    "    \n",
    "    # We only want first image, break loop\n",
    "    break\n",
    "\n",
    "print(featured_image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sol 2319 (2019-02-13), high -17C/1F, low -72C/-97F, pressure at 8.12 hPa, daylight 06:46-18:52pic.twitter.com/anlHR95BMs\n"
     ]
    }
   ],
   "source": [
    "# Mars Weather\n",
    "# HTML object\n",
    "url = \"https://twitter.com/marswxreport?lang=en\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve tweet information\n",
    "tweets = soup.find_all(\"p\", class_=\"TweetTextSize TweetTextSize--normal js-tweet-text tweet-text\")\n",
    "\n",
    "for tweet in tweets:\n",
    "    # Specify tweet information\n",
    "    tweet_txt = tweet.text\n",
    "    \n",
    "    # We only want first tweet, break loop\n",
    "    if \"Sol\" in tweet_txt:\n",
    "        break\n",
    "    \n",
    "print(tweet_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>0</th>\\n      <th>1</th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>0</th>\\n      <td>Equatorial Diameter:</td>\\n      <td>6,792 km</td>\\n    </tr>\\n    <tr>\\n      <th>1</th>\\n      <td>Polar Diameter:</td>\\n      <td>6,752 km</td>\\n    </tr>\\n    <tr>\\n      <th>2</th>\\n      <td>Mass:</td>\\n      <td>6.42 x 10^23 kg (10.7% Earth)</td>\\n    </tr>\\n    <tr>\\n      <th>3</th>\\n      <td>Moons:</td>\\n      <td>2 (Phobos &amp; Deimos)</td>\\n    </tr>\\n    <tr>\\n      <th>4</th>\\n      <td>Orbit Distance:</td>\\n      <td>227,943,824 km (1.52 AU)</td>\\n    </tr>\\n    <tr>\\n      <th>5</th>\\n      <td>Orbit Period:</td>\\n      <td>687 days (1.9 years)</td>\\n    </tr>\\n    <tr>\\n      <th>6</th>\\n      <td>Surface Temperature:</td>\\n      <td>-153 to 20 Â°C</td>\\n    </tr>\\n    <tr>\\n      <th>7</th>\\n      <td>First Record:</td>\\n      <td>2nd millennium BC</td>\\n    </tr>\\n    <tr>\\n      <th>8</th>\\n      <td>Recorded By:</td>\\n      <td>Egyptian astronomers</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mars Facts\n",
    "# HTML object\n",
    "url = \"http://space-facts.com/mars/\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Retrieve table information\n",
    "tables = pd.read_html(url)\n",
    "\n",
    "# Convert the table to an HTML string\n",
    "mars_table = tables[0].to_html()\n",
    "mars_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mars Hemispheres\n",
    "hemisphere_image_urls = []\n",
    "\n",
    "# HTML object\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# First Hemisphere\n",
    "url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/cerberus_enhanced\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "hemi = soup.find_all(\"h2\", class_=\"title\")\n",
    "hemi_name = hemi[0].text\n",
    "hemi_name = hemi_name[:-9]\n",
    "\n",
    "div = soup.find(\"div\", class_=\"downloads\")\n",
    "\n",
    "for div in div:\n",
    "    link = div.find(\"a\")\n",
    "    \n",
    "    if type(link) != type(1) and type(link) != type(None):\n",
    "        img_url = link[\"href\"]\n",
    "        \n",
    "# Add extracted info to dictionary\n",
    "hemi_dict = {\"title\":hemi_name, \"image_url\":img_url}\n",
    "hemisphere_image_urls.append(hemi_dict)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Second Hemisphere\n",
    "url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/schiaparelli_enhanced\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "hemi = soup.find_all(\"h2\", class_=\"title\")\n",
    "hemi_name = hemi[0].text\n",
    "hemi_name = hemi_name[:-9]\n",
    "\n",
    "div = soup.find(\"div\", class_=\"downloads\")\n",
    "\n",
    "for div in div:\n",
    "    link = div.find(\"a\")\n",
    "    \n",
    "    if type(link) != type(1) and type(link) != type(None):\n",
    "        img_url = link[\"href\"]\n",
    "        \n",
    "# Add extracted info to dictionary\n",
    "hemi_dict = {\"title\":hemi_name, \"image_url\":img_url}\n",
    "hemisphere_image_urls.append(hemi_dict)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Third Hemisphere\n",
    "url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/syrtis_major_enhanced\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "hemi = soup.find_all(\"h2\", class_=\"title\")\n",
    "hemi_name = hemi[0].text\n",
    "hemi_name = hemi_name[:-9]\n",
    "\n",
    "div = soup.find(\"div\", class_=\"downloads\")\n",
    "\n",
    "for div in div:\n",
    "    link = div.find(\"a\")\n",
    "    \n",
    "    if type(link) != type(1) and type(link) != type(None):\n",
    "        img_url = link[\"href\"]\n",
    "        \n",
    "# Add extracted info to dictionary\n",
    "hemi_dict = {\"title\":hemi_name, \"image_url\":img_url}\n",
    "hemisphere_image_urls.append(hemi_dict)\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------------------------------------\n",
    "# Fourth Hemisphere\n",
    "url = \"https://astrogeology.usgs.gov/search/map/Mars/Viking/valles_marineris_enhanced\"\n",
    "browser.visit(url)\n",
    "html = browser.html\n",
    "\n",
    "# Parse HTML with Beautiful Soup\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "hemi = soup.find_all(\"h2\", class_=\"title\")\n",
    "hemi_name = hemi[0].text\n",
    "hemi_name = hemi_name[:-9]\n",
    "\n",
    "div = soup.find(\"div\", class_=\"downloads\")\n",
    "\n",
    "for div in div:\n",
    "    link = div.find(\"a\")\n",
    "    \n",
    "    if type(link) != type(1) and type(link) != type(None):\n",
    "        img_url = link[\"href\"]\n",
    "        \n",
    "# Add extracted info to dictionary\n",
    "hemi_dict = {\"title\":hemi_name, \"image_url\":img_url}\n",
    "hemisphere_image_urls.append(hemi_dict)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
